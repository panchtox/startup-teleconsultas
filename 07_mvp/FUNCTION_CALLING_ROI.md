# Sistema de Function Calling para CÃ¡lculos de ROI

## ðŸ“‹ Resumen

Implementamos **function calling** de OpenAI para que el LLM use funciones JavaScript precisas cuando necesita hacer cÃ¡lculos de ROI, en lugar de hacer matemÃ¡tica aproximada.

## ðŸŽ¯ Problema que Resuelve

**Antes:** El LLM hacÃ­a cÃ¡lculos mentales que a menudo confundÃ­an:
- Consultas totales vs consultas perdidas
- Revenue vs profit
- CÃ¡lculos de porcentajes incorrectos

**Ahora:** El LLM detecta automÃ¡ticamente cuÃ¡ndo necesita calcular ROI y llama a una funciÃ³n JavaScript precisa.

## ðŸ—ï¸ Arquitectura

```
Usuario pregunta: "Â¿CuÃ¡nto puedo ahorrar?"
          â†“
Frontend envÃ­a mensaje al backend
          â†“
Backend â†’ LLM (gpt-4o-mini con functions)
          â†“
LLM detecta que necesita calculate_roi()
          â†“
Backend ejecuta roiCalculations.js
          â†“
Backend devuelve resultado al LLM
          â†“
LLM interpreta resultado y responde en lenguaje natural
          â†“
Frontend muestra respuesta al usuario
```

## ðŸ“ Archivos Creados/Modificados

### 1. `utils/roiCalculations.js` (NUEVO)

Script con 3 funciones:

#### `calculateROI(params)`
FunciÃ³n principal que calcula todo el ROI.

**ParÃ¡metros requeridos:**
- `monthlyAppointments`: Consultas mensuales totales
- `revenuePerAppointment`: Ingreso por consulta ($)
- `costPerAppointment`: Costo mÃ©dico por consulta ($)

**ParÃ¡metros opcionales:**
- `currentNoShowRate`: Tasa actual de ausentismo (default: 0.33 = 33%)
- `targetNoShowRate`: Tasa objetivo con TeleAssist (default: 0.08 = 8%)

**Retorna objeto con:**
```javascript
{
  inputs: { ... },              // ParÃ¡metros de entrada
  current: { ... },             // SituaciÃ³n actual sin TeleAssist
  target: { ... },              // SituaciÃ³n con TeleAssist
  improvements: { ... },        // Mejoras y ahorros brutos
  costs: { ... },               // Costos de TeleAssist
  netROI: { ... }               // ROI neto final
}
```

**CÃ¡lculos clave:**
- âœ… Consultas perdidas actuales vs objetivo
- âœ… PÃ©rdida econÃ³mica por no-shows
- âœ… Ahorro mensual y anual
- âœ… Costo estimado de TeleAssist (basado en $0.75/paciente/mes)
- âœ… ROI neto (ahorro - costo)
- âœ… MÃºltiplo de retorno (ej: 17x)
- âœ… Periodo de recuperaciÃ³n (meses)

#### `generateROISummary(roiData)`
Convierte el objeto de ROI en texto formateado legible.

#### `calculateScenarios()`
Pre-calcula ROI para 4 escenarios tÃ­picos:
- ClÃ­nica PequeÃ±a (200 consultas/mes)
- ClÃ­nica Mediana (500 consultas/mes)
- ClÃ­nica Grande (1000 consultas/mes)
- Red de ClÃ­nicas (3000 consultas/mes)

### 2. `routes/chat.js` (MODIFICADO)

Agregado:

1. **Import del mÃ³dulo de cÃ¡lculos:**
```javascript
const { calculateROI, generateROISummary } = require('../utils/roiCalculations');
```

2. **DefiniciÃ³n de funciÃ³n para el LLM:**
```javascript
const FUNCTIONS = [
  {
    name: 'calculate_roi',
    description: 'Calcula el ROI preciso...',
    parameters: { ... } // Esquema JSON con los parÃ¡metros
  }
];
```

3. **System prompt actualizado:**
Instruye explÃ­citamente al LLM:
- SIEMPRE usar `calculate_roi` para preguntas sobre ahorros
- NUNCA hacer cÃ¡lculos manuales
- Preguntar por datos faltantes si es necesario

4. **Function calling en `handleChat()`:**
```javascript
// Primera llamada con functions disponibles
response = await client.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: messages,
  functions: FUNCTIONS,
  function_call: 'auto', // El LLM decide cuÃ¡ndo llamar
  ...
});

// Si el LLM llamÃ³ una funciÃ³n
if (assistantMessage.function_call) {
  // Ejecutar la funciÃ³n JavaScript
  const result = executeFunctionCall(name, args);
  
  // Segunda llamada para que interprete el resultado
  response = await client.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [..., { role: 'function', content: result }],
    ...
  });
}
```

5. **FunciÃ³n `executeFunctionCall()`:**
Ejecuta la funciÃ³n solicitada por el LLM y maneja errores.

## ðŸ”„ Flujo de ConversaciÃ³n Ejemplo

**Usuario:** "Tengo 500 consultas al mes, cobro $60 por consulta y le pago $35 al mÃ©dico. Â¿CuÃ¡nto puedo ahorrar?"

**1. Primera llamada al LLM:**
```json
{
  "messages": [...],
  "functions": [{ "name": "calculate_roi", ... }],
  "function_call": "auto"
}
```

**2. LLM responde con function_call:**
```json
{
  "function_call": {
    "name": "calculate_roi",
    "arguments": "{\"monthlyAppointments\": 500, \"revenuePerAppointment\": 60, \"costPerAppointment\": 35}"
  }
}
```

**3. Backend ejecuta la funciÃ³n:**
```javascript
const result = calculateROI({
  monthlyAppointments: 500,
  revenuePerAppointment: 60,
  costPerAppointment: 35
});
// result contiene todos los cÃ¡lculos precisos
```

**4. Segunda llamada al LLM con el resultado:**
```json
{
  "messages": [
    ...,
    { "role": "function", "name": "calculate_roi", "content": "{...resultado...}" }
  ]
}
```

**5. LLM interpreta y responde en lenguaje natural:**
"Excelente pregunta! Con 500 consultas mensuales... [explica el ROI de forma clara]"

## ðŸŽ“ CÃ³mo el LLM Decide Usar la FunciÃ³n

El LLM usa `calculate_roi` cuando detecta:

âœ… **Triggers positivos:**
- "Â¿CuÃ¡nto puedo ahorrar?"
- "Â¿CuÃ¡l es el ROI?"
- "Â¿Vale la pena econÃ³micamente?"
- "Â¿CuÃ¡nto dinero ganarÃ©?"
- "MuÃ©strame el retorno de inversiÃ³n"

âœ… **Datos necesarios:**
- Si el usuario ya dio los 3 parÃ¡metros â†’ Llama la funciÃ³n directamente
- Si faltan datos â†’ Pregunta primero

âŒ **No usa la funciÃ³n para:**
- Preguntas generales sobre features
- Explicaciones de cÃ³mo funciona el sistema
- Acciones en la plataforma

## ðŸ“Š Ejemplo de Resultado

Input:
```javascript
{
  monthlyAppointments: 500,
  revenuePerAppointment: 60,
  costPerAppointment: 35
}
```

Output (resumido):
```
SITUACIÃ“N ACTUAL: 165 consultas perdidas/mes, $5,775 de pÃ©rdida mensual
SITUACIÃ“N CON TELEASSIST: 40 consultas perdidas/mes
AHORRO: 125 consultas recuperadas, $37,500/aÃ±o de ahorro bruto
COSTO TELEASSIST: $4,980/aÃ±o
ROI NETO: $32,520/aÃ±o de ahorro neto (17.2x retorno)
```

## ðŸ§ª Testing

### Test local antes de deploy:

1. **Test del script de cÃ¡lculos:**
```javascript
// En backend/utils/
const { calculateROI, generateROISummary } = require('./roiCalculations');

const result = calculateROI({
  monthlyAppointments: 500,
  revenuePerAppointment: 60,
  costPerAppointment: 35
});

console.log(generateROISummary(result));
```

2. **Test del endpoint de chat:**
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Tengo 500 consultas mensuales, cobro $60 por consulta y pago $35 al mÃ©dico. CuÃ¡nto puedo ahorrar?"
  }'
```

3. **Test en frontend:**
Abre el chat y pregunta directamente sobre ROI.

### Validaciones en el cÃ³digo:

El script valida:
- âœ… `monthlyAppointments > 0`
- âœ… `revenuePerAppointment > 0`
- âœ… `costPerAppointment >= 0`
- âœ… `costPerAppointment < revenuePerAppointment`

Si algo falla, devuelve error legible.

## ðŸš€ Deploy

### Backend (Render):
```bash
cd C:\00_dev\00_playground\startup-teleconsultas\07_mvp\backend
git add utils/roiCalculations.js routes/chat.js
git commit -m "Add function calling for precise ROI calculations"
git push origin feature/chat-llm
```

Render auto-deploya desde el branch.

### Frontend (sin cambios necesarios):
El frontend no requiere modificaciones. Funciona igual, pero ahora recibe respuestas mÃ¡s precisas.

## ðŸ“ˆ Mejoras Futuras

1. **MÃ¡s funciones:**
   - `get_patient_stats()` â†’ Stats de pacientes
   - `get_appointment_trends()` â†’ Tendencias de consultas
   - `suggest_improvements()` â†’ Sugerencias personalizadas

2. **CachÃ© de resultados:**
   - Guardar cÃ¡lculos frecuentes en Redis
   - Reducir llamadas al LLM

3. **ValidaciÃ³n de inputs:**
   - Detectar monedas (USD vs ARS)
   - Sugerir rangos tÃ­picos si los nÃºmeros parecen atÃ­picos

4. **UI especializada:**
   - Mostrar tabla de ROI en el chat
   - GrÃ¡ficos inline con los cÃ¡lculos

## ðŸ› Troubleshooting

**Problema:** LLM no llama a la funciÃ³n
- **Causa:** System prompt no enfatiza suficiente
- **Fix:** Actualizar SYSTEM_PROMPT con mÃ¡s Ã©nfasis

**Problema:** CÃ¡lculos incorrectos
- **Causa:** Bug en roiCalculations.js
- **Fix:** Test unitarios del script primero

**Problema:** Rate limit 429
- **Causa:** Function calling usa 2 requests (ida y vuelta)
- **Fix:** Implementar rate limiting interno

**Problema:** Frontend muestra error
- **Causa:** Backend no deployado o variable de entorno faltante
- **Fix:** Verificar GITHUB_TOKEN en Render

## ðŸ“š Referencias

- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [GitHub Models API](https://docs.github.com/en/github-models)
- [Azure AI Inference (mismo formato)](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling)

---

**Creado:** 12 Noviembre 2025  
**Status:** âœ… Implementado, listo para testing  
**PrÃ³ximo paso:** Deploy y test en producciÃ³n
